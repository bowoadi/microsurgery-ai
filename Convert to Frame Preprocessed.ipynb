{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5966cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ab58bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total frames: 72.0\n"
     ]
    }
   ],
   "source": [
    "max_frame = 12 * 30 # 12s * 30 fps\n",
    "frame_skip = 5\n",
    "frame_size = 256\n",
    "parted = True\n",
    "print(\"Total frames:\", max_frame / frame_skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5975c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def load_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(f\"Cannot open video {video_path}\")\n",
    "\n",
    "    frames = []\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Ensure that it is in RGB and resize to frame_sizexframe_size\n",
    "        if ret:\n",
    "            # frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame = cv2.resize(frame, (frame_size, frame_size))\n",
    "        else:\n",
    "            break\n",
    "\n",
    "        frames.append(frame)\n",
    "\n",
    "    cap.release()\n",
    "    return frames\n",
    "\n",
    "def load_video_tensor(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise IOError(f\"Cannot open video {video_path}\")\n",
    "\n",
    "    frames = []\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Ensure that it is in RGB and resize to frame_sizexframe_size\n",
    "        if ret:\n",
    "            # frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame = cv2.resize(frame, (frame_size, frame_size))\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "        frame_tensor = torch.tensor(frame, dtype=torch.uint8)\n",
    "        frames.append(frame_tensor)\n",
    "\n",
    "    cap.release()\n",
    "    frames = torch.stack(frames)\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1166d1d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Efficiency - Always pulls out of field_5',\n",
       " 'Efficiency - Does not pull needle out of field_1',\n",
       " 'Efficiency - Grasps once only_5',\n",
       " 'Efficiency - Many wasted moves_1',\n",
       " 'Efficiency - No wasted moves_5',\n",
       " 'Efficiency - Regrasps multiple times_1',\n",
       " 'Efficiency - Regrasps occasionally_3',\n",
       " 'Efficiency - Some wasted moves_3',\n",
       " 'Efficiency - Sometimes pulls needle out of field_3',\n",
       " 'Handling - A few passes_3',\n",
       " 'Handling - Always bolsters_5',\n",
       " 'Handling - Always pull needle out on the curve_5',\n",
       " 'Handling - Does not bolster_1',\n",
       " 'Handling - Grasps tip of needle_1',\n",
       " 'Handling - Multiple passes_1',\n",
       " 'Handling - Never grasps the tip_5',\n",
       " 'Handling - Pulls needle out not on the curve_1',\n",
       " 'Handling - Single passes_5',\n",
       " 'Handling - Sometimes bolsters_3',\n",
       " 'Handling - Sometimes grasps the tip_3',\n",
       " 'Handling - Sometimes pulls needle out on the curve_3',\n",
       " 'Preparation - Approximating clamp applied correctly_5',\n",
       " 'Preparation - Background in place_5',\n",
       " 'Preparation - Clean adventitial stripping_5',\n",
       " 'Preparation - Ends set up poorly in approximating clamp_1',\n",
       " 'Preparation - Excessive inadequate adventitial stripping_3',\n",
       " 'Preparation - Forgets Background_1',\n",
       " 'Preparation - Forgets dilatation_1',\n",
       " 'Preparation - Gentle dilatation_5',\n",
       " 'Preparation - No adventitial stripping_1',\n",
       " 'Preparation - Rough dilatation_3',\n",
       " 'Quality of Knot - Cut ends OK length_3',\n",
       " 'Quality of Knot - Cut ends proper length_5',\n",
       " 'Quality of Knot - Cut ends too long short_1',\n",
       " 'Quality of Knot - Loose_1',\n",
       " 'Quality of Knot - Not square_1',\n",
       " 'Quality of Knot - Partially square_3',\n",
       " 'Quality of Knot - Snug_5',\n",
       " 'Quality of Knot - Somewhat loose_3',\n",
       " 'Quality of Knot - Square_5']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = False\n",
    "input_folder = \"../data_full_backup\"\n",
    "output_folder = f\"data_frameskip_{frame_skip}_{max_frame//30}s{'_tensor' if tensor else ''}{'' if parted else '_unparted'}_{frame_size}size\"\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "else:\n",
    "    if os.listdir(output_folder):\n",
    "        print(f\"Output folder {output_folder} is not empty. Continue? (y/n)\")\n",
    "        if input().lower() != 'y':\n",
    "            exit()\n",
    "os.listdir(input_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c789303",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "metadata = []\n",
    "\n",
    "def task(microsurgery_class, sub_microsurgery_class, video_name_file):\n",
    "    frames = load_video(f\"{input_folder}/\"+microsurgery_class+\"/\"+sub_microsurgery_class+\"/\"+video_name_file)\n",
    "    metadata.append({\n",
    "        \"path\": f\"{output_folder}/\"+microsurgery_class+\"/\"+sub_microsurgery_class+\"/\"+video_name_file,\n",
    "        \"frames\": len(frames)\n",
    "    })\n",
    "    \n",
    "    if os.path.exists(f\"{output_folder}/\"+microsurgery_class) == False:\n",
    "        os.mkdir(f\"{output_folder}/\"+microsurgery_class)\n",
    "\n",
    "    if os.path.exists(f\"{output_folder}/\"+microsurgery_class+\"/\"+sub_microsurgery_class) == False:\n",
    "        os.mkdir(f\"{output_folder}/\"+microsurgery_class+\"/\"+sub_microsurgery_class)\n",
    "\n",
    "    total_parts = len(frames) // max_frame\n",
    "    # total_parts = 1\n",
    "    for index, part in enumerate(range(1, total_parts+1)):\n",
    "        if os.path.exists(f\"{output_folder}/\"+microsurgery_class+\"/\"+sub_microsurgery_class+\"/\"+video_name_file+\"_\"+str(part)) == False:\n",
    "            os.mkdir(f\"{output_folder}/\"+microsurgery_class+\"/\"+sub_microsurgery_class+\"/\"+video_name_file+\"_\"+str(part))\n",
    "\n",
    "        for index, frame in enumerate(frames[index * max_frame: max_frame * part: frame_skip]):\n",
    "            cv2.imwrite(f\"{output_folder}/\"+microsurgery_class+\"/\"+sub_microsurgery_class+\"/\"+video_name_file+\"_\"+str(part)+\"/image_\"+str(index)+\".jpg\", frame)\n",
    "\n",
    "\n",
    "def no_subclass(microsurgery_class, video_name_file):\n",
    "    frames = load_video(f\"{input_folder}/\"+microsurgery_class+\"/\"+video_name_file)\n",
    "    metadata.append({\n",
    "        \"path\": f\"{output_folder}/\"+microsurgery_class+\"/\"+video_name_file,\n",
    "        \"frames\": len(frames)\n",
    "    })\n",
    "    if os.path.exists(f\"{output_folder}/\"+microsurgery_class) == False:\n",
    "        os.mkdir(f\"{output_folder}/\"+microsurgery_class)\n",
    "\n",
    "    total_parts = len(frames) // max_frame\n",
    "    # total_parts = 1\n",
    "    for index, part in enumerate(range(1, total_parts+1)):\n",
    "        if os.path.exists(f\"{output_folder}/\"+microsurgery_class+\"/\"+video_name_file+\"_\"+str(part)) == False:\n",
    "            os.mkdir(f\"{output_folder}/\"+microsurgery_class+\"/\"+video_name_file+\"_\"+str(part))\n",
    "\n",
    "        for index, frame in enumerate(frames[index * max_frame: max_frame * part: frame_skip]):\n",
    "            cv2.imwrite(f\"{output_folder}/\"+microsurgery_class+\"/\"+video_name_file+\"_\"+str(part)+\"/image_\"+str(index)+\".jpg\", frame)\n",
    "\n",
    "def no_subclass_no_parting(microsurgery_class, video_name_file):\n",
    "    frames = load_video(f\"{input_folder}/\"+microsurgery_class+\"/\"+video_name_file)\n",
    "    metadata.append({\n",
    "        \"path\": f\"{output_folder}/\"+microsurgery_class+\"/\"+video_name_file,\n",
    "        \"frames\": len(frames)\n",
    "    })\n",
    "    if os.path.exists(f\"{output_folder}/\"+microsurgery_class) == False:\n",
    "        os.mkdir(f\"{output_folder}/\"+microsurgery_class)\n",
    "\n",
    "    total_parts = len(frames) // max_frame\n",
    "    # total_parts = 1\n",
    "    for index, part in enumerate(range(1, total_parts+1)):\n",
    "        if os.path.exists(f\"{output_folder}/\"+microsurgery_class+\"/\"+video_name_file) == False:\n",
    "            os.mkdir(f\"{output_folder}/\"+microsurgery_class+\"/\"+video_name_file)\n",
    "\n",
    "        for idx, frame in enumerate(frames[index * max_frame: max_frame * part: frame_skip], start=max_frame * (part-1) // frame_skip):\n",
    "            cv2.imwrite(f\"{output_folder}/\"+microsurgery_class+\"/\"+video_name_file+\"/image_\"+str(idx)+\".jpg\", frame)\n",
    "\n",
    "\n",
    "def as_tensor(microsurgery_class, video_name_file):\n",
    "    frames = load_video_tensor(f\"{input_folder}/\"+microsurgery_class+\"/\"+video_name_file)\n",
    "    if os.path.exists(f\"{output_folder}/\"+microsurgery_class) == False:\n",
    "        os.mkdir(f\"{output_folder}/\"+microsurgery_class)\n",
    "\n",
    "    total_parts = len(frames) // max_frame\n",
    "    if total_parts == 0:\n",
    "        total_parts = 1\n",
    "    # total_parts = 1\n",
    "    for index, part in enumerate(range(1, total_parts+1)):\n",
    "        torch.save(frames[index * max_frame: max_frame * part: frame_skip], f\"{output_folder}/\"+microsurgery_class+\"/\"+video_name_file+\"_\"+str(part)+\".pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "688af8f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Efficiency - Always pulls out of field_5\n",
      "Efficiency - Does not pull needle out of field_1\n",
      "Efficiency - Grasps once only_5\n",
      "Efficiency - Many wasted moves_1\n",
      "Efficiency - No wasted moves_5\n",
      "Efficiency - Regrasps multiple times_1\n",
      "Efficiency - Regrasps occasionally_3\n",
      "Efficiency - Some wasted moves_3\n",
      "Efficiency - Sometimes pulls needle out of field_3\n",
      "Handling - A few passes_3\n",
      "Handling - Always bolsters_5\n",
      "Handling - Always pull needle out on the curve_5\n",
      "Handling - Does not bolster_1\n",
      "Handling - Grasps tip of needle_1\n",
      "Handling - Multiple passes_1\n",
      "Handling - Never grasps the tip_5\n",
      "Handling - Pulls needle out not on the curve_1\n",
      "Handling - Single passes_5\n",
      "Handling - Sometimes bolsters_3\n",
      "Handling - Sometimes grasps the tip_3\n",
      "Handling - Sometimes pulls needle out on the curve_3\n",
      "Preparation - Approximating clamp applied correctly_5\n",
      "Preparation - Background in place_5\n",
      "Preparation - Clean adventitial stripping_5\n",
      "Preparation - Ends set up poorly in approximating clamp_1\n",
      "Preparation - Excessive inadequate adventitial stripping_3\n",
      "Preparation - Forgets Background_1\n",
      "Preparation - Forgets dilatation_1\n",
      "Preparation - Gentle dilatation_5\n",
      "Preparation - No adventitial stripping_1\n",
      "Preparation - Rough dilatation_3\n",
      "Quality of Knot - Cut ends OK length_3\n",
      "Quality of Knot - Cut ends proper length_5\n",
      "Quality of Knot - Cut ends too long short_1\n",
      "Quality of Knot - Loose_1\n",
      "Quality of Knot - Not square_1\n",
      "Quality of Knot - Partially square_3\n",
      "Quality of Knot - Snug_5\n",
      "Quality of Knot - Somewhat loose_3\n",
      "Quality of Knot - Square_5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 375/375 [00:00<00:00, 374759.11it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# job_list = []\n",
    "# with ThreadPoolExecutor(10) as executor:\n",
    "#     for microsurgery_class in os.listdir(f\"{input_folder}\"):\n",
    "#         print(microsurgery_class)\n",
    "#         for sub_microsurgery_class in os.listdir(f\"{input_folder}/\"+microsurgery_class):\n",
    "#             for video_name_file in os.listdir(f\"{input_folder}/\"+microsurgery_class+\"/\"+sub_microsurgery_class):\n",
    "#                 job = executor.submit(task, microsurgery_class, sub_microsurgery_class, video_name_file)\n",
    "\n",
    "#                 job_list.append(job)\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "job_list = []\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    for microsurgery_class in os.listdir(f\"{input_folder}\"):\n",
    "        print(microsurgery_class)\n",
    "        for video_name_file in os.listdir(f\"{input_folder}/\"+microsurgery_class):\n",
    "            if tensor:\n",
    "                job = executor.submit(as_tensor, microsurgery_class, video_name_file)\n",
    "            else: \n",
    "                if parted:\n",
    "                    job = executor.submit(no_subclass, microsurgery_class, video_name_file)\n",
    "                else:\n",
    "                    job = executor.submit(no_subclass_no_parting, microsurgery_class, video_name_file)\n",
    "            job_list.append(job)\n",
    "\n",
    "\n",
    "for job in tqdm(job_list):\n",
    "    job.result() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ea5adc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>frames</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data_frameskip_5_12s_256size/Efficiency - Alwa...</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data_frameskip_5_12s_256size/Efficiency - Does...</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data_frameskip_5_12s_256size/Efficiency - Alwa...</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>data_frameskip_5_12s_256size/Efficiency - Does...</td>\n",
       "      <td>327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>data_frameskip_5_12s_256size/Efficiency - Does...</td>\n",
       "      <td>371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>data_frameskip_5_12s_256size/Preparation - For...</td>\n",
       "      <td>7680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>data_frameskip_5_12s_256size/Quality of Knot -...</td>\n",
       "      <td>2545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>data_frameskip_5_12s_256size/Quality of Knot -...</td>\n",
       "      <td>3702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>data_frameskip_5_12s_256size/Quality of Knot -...</td>\n",
       "      <td>2766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>data_frameskip_5_12s_256size/Preparation - No ...</td>\n",
       "      <td>9016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>375 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  path  frames\n",
       "0    data_frameskip_5_12s_256size/Efficiency - Alwa...     243\n",
       "1    data_frameskip_5_12s_256size/Efficiency - Does...     243\n",
       "2    data_frameskip_5_12s_256size/Efficiency - Alwa...     252\n",
       "3    data_frameskip_5_12s_256size/Efficiency - Does...     327\n",
       "4    data_frameskip_5_12s_256size/Efficiency - Does...     371\n",
       "..                                                 ...     ...\n",
       "370  data_frameskip_5_12s_256size/Preparation - For...    7680\n",
       "371  data_frameskip_5_12s_256size/Quality of Knot -...    2545\n",
       "372  data_frameskip_5_12s_256size/Quality of Knot -...    3702\n",
       "373  data_frameskip_5_12s_256size/Quality of Knot -...    2766\n",
       "374  data_frameskip_5_12s_256size/Preparation - No ...    9016\n",
       "\n",
       "[375 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(metadata)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e213e40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(f\"{output_folder}/metadata.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3df7bd88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "path      254\n",
       "frames    254\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib\n",
    "df[df[\"frames\"] > 20 * 30].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "c327c6d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUoAAAGVCAYAAACYQbj/AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAABlVJREFUeJzt3TFKJGsYhtF/LiID05EmbTDuxXWYzSomUjRyFWauw+VoYkW/ICZ9VzA8cLltTes5G/heuuGBooL6ttvtdgOAP/pn7QEAfzuhBAhCCRCEEiAIJUAQSoAglABBKAGCUAIEoQQIQgkQhBIgCCVAEEqAIJQAQSgBglACBKEECEIJEIQSIAglQBBKgCCUAEEoAYJQAgShBAhCCRCEEiAIJUAQSoAglABBKAGCUAIEoQQIQgkQhBIgCCVAEEqAIJQAQSgBglACBKEECEIJEIQSIAglQBBKgCCUAEEoAYJQAgShBAhCCRCEEiAIJUAQSoAglABBKAGCUAIEoQQIQgkQhBIgCCVAEEqAIJQAQSgBglACBKEECEIJEIQSIAglQBBKgCCUAEEoAYJQAgShBAhCCRCEEiAIJUAQSoAglABBKAGCUAIEoQQIQgkQhBIgCCVAEEqAIJQAQSgBglACBKEECEIJEIQSIAglQBBKgCCUAEEoAYJQAgShBAhCCRCEEiAIJUAQSoAglABBKAGCUAIEoQQIQgkQhBIgCCVAEEqAIJQAQSgBglACBKEECEIJEIQSIAglQBBKgCCUAEEoAYJQAgShBAhCCRCEEiAIJUAQSoAglABBKAGCUAIEoQQIQgkQhBIgCCVAEEqAIJQAQSgBglACBKEECEIJEIQSIAglQBBKgCCUAEEoAYJQAgShBAhCCRCEEiAIJUAQSoAglABBKAGCUAIEoQQIQgkQhBIgCCVAEEqAIJQAQSgBglACBKEECEIJEIQSIAglQBBKgCCUAEEoAYJQAgShBAhCCRCEEiAIJUAQSoAglABBKAGCUAIEoQQIQgkQhBIgCCVAEEqAIJQAQSgBglACBKEECEIJEIQSIAglQBBKgCCUAEEoAYJQAgShBAhCCRCEEiAIJUAQSoAglABBKAGCUAIEoQQIQgkQhBIgCCVAEEqAIJQAQSgBglACBKEECEIJEIQSIAglQBBKgCCUAEEoAYJQAgShBAhCCRCEEiAIJUAQSoAglABBKAGCUAKEo7UH8PGWZRlzzrVnHKzNZjNOTk7WnsEHEsovZlmW8fvqery+va895WD9+H487m5vxPILEcovZs45Xt/ex8Xlr3G6PVt7zsF5eX4ajw/3Y84plF+IUH5Rp9uzsf15vvYMOAhe5gAEoQQIQgkQhBIgCCVAEEqAIJQAQSgBglACBKEECEIJEIQSIAglQBBKgCCUAEEoAYJQAgShBAhCCRCEEiAIJUDwFUZY2bIsY8659oyDttls9vr5YKGEFS3LMn5fXY/Xt/e1pxy0H9+Px93tzd5iKZSwojnneH17HxeXv8bp9mztOQfp5flpPD7cjzmnUMJndro9G9uf52vP4A+8zAEIQgkQhBIgCCVAEEqAIJQAQSgBglACBKEECEIJEIQSIAglQBBKgCCUAEEoAYJQAgShBAhCCRCEEiAIJUAQSoAglABBKAGCUAIEoQQIQgkQhBIgCCVAEEqAIJQAQSgBglACBKEECEIJEIQSIAglQBBKgCCUAEEoAYJQAgShBAhCCRCEEiAIJUAQSoAglABBKAGCUAIEoQQIQgkQhBIgCCVAEEqAIJQAQSgBglACBKEECEIJEIQSIAglQBBKgCCUAEEoAYJQAgShBAhH+z6wLMuYc+77zKe22WzGycnJ2jPgy9prKJdlGb+vrsfr2/s+z3x6P74fj7vbG7GElew1lHPO8fr2Pi4uf43T7dk+T31aL89P4/Hhfsw5hRJWsvdH7zHGON2eje3P8484BfC/8zIHIAglQBBKgCCUAEEoAYJQAgShBAhCCRCEEiAIJUAQSoAglABBKAGCUAIEoQQIQgkQhBIgCCVAEEqAIJQAQSgBglACBKEECEIJEIQSIAglQBBKgCCUAEEoAYJQAgShBAhCCRCEEiAIJUAQSoAglABBKAGCUAIEoQQIQgkQhBIgCCVAEEqAIJQAQSgBglACBKEECEIJEIQSIAglQBBKgCCUAEEoAYJQAgShBAhCCRCEEiAIJUAQSoAglABBKAGCUAIEoQQIQgkQhBIgCCVAEEqAIJQAQSgBglAChKOPOPLy/PQRZz6lff12/pP/xv/x9/mI3+7bbrfb7f0KwAHz6A0QhBIgCCVAEEqAIJQAQSgBglACBKEECEIJEP4F/u9253vg8ZoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 400x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define the blue color variant based on the provided code 'A0ECFF'\n",
    "blue_color = '#A0ECFF'\n",
    "\n",
    "# Generate 6 additional random softmax probabilities for the example\n",
    "probabilities_list = []\n",
    "for _ in range(1):\n",
    "    class_1 = np.random.rand(1)\n",
    "    class_2 = np.random.rand(1)\n",
    "    class_3 = np.random.rand(1)\n",
    "\n",
    "    # Applying softmax function to get probabilities\n",
    "    probabilities = np.exp([class_1, class_2, class_3]) / np.sum(np.exp([class_1, class_2, class_3]))\n",
    "    probabilities_list.append(probabilities.flatten())\n",
    "\n",
    "# Create the figure\n",
    "fig, ax = plt.subplots(figsize=(4, 5))\n",
    "\n",
    "# Plot each set of probabilities\n",
    "for i, probabilities in enumerate(probabilities_list):\n",
    "    \n",
    "    ax.bar(['Class 1', 'Class 2', 'Class 3'], probabilities, color=blue_color, edgecolor='black', alpha=0.6, label=f'Sample {i+1}')\n",
    "\n",
    "# Remove grid and title\n",
    "ax.grid(False)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_title('')\n",
    "ax.axis('off')\n",
    "# ax.set_xticklabels([])\n",
    "# ax.set_yticklabels([])\n",
    "\n",
    "# Show only the probability ticks\n",
    "ax.set_ylabel('')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "microsurgery",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
